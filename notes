framebuffer-draw

Cubemaps: reflective surfaces

https://learnopengl.com/Advanced-OpenGL/Cubemaps
this uses framebuffer cubes.

There is a huge difference between capturing the framebuffer vs drawing the quad with the framebuffer as the texture.
For both parts, iterate through all the framebuffers, but iterate through each step separately. 
We want to create two Framebuffer objects within the vector, and then we want to draw both of them onto the screen.
- this is because capturing the framebuffer just captures whatever is currently set to be rendered.
- capturing the framebuffer is capturing the raw world, we want to make sure we capture the view of the world before we create the textured quad with the framebuffer

Next step: we want a camera that can have its own direction(it can point backwards, for example)
- Add a new function to the Camera, SetCameraEyeDirection
- Add a second camera to Renderer
- Set the direction of the second camera to be backwards, and update input to apply input to the second camera too in SDLGraphicsProgram

Updating models based on camera position occurs in SceneNodes, (WE DO NOT NEED TO COPY SINCE THE SHADER UNIFORMS CAN EASILY BE REMADE FROM ANOTHER CAMERA'S PERSPECTIVE, USING UPDATE IN SCENENODE UPDATES THE SHADER UNIFORMS, NOT THE OBJECT DATA AND COORDINATES ITSELF)
- When we call Update using another camera, we simply overwrite the previous shader uniforms from a previous camera. The previous shader's data is recoverable as long as the previous camera is used to call Update again.
- All update does is fetch MVP matrices and camera data into the shader uniforms passed into OpenGL for calculation, it doesn't actually calculate anything without OpenGL. 
- Then, make sure that there is a field within the FrameBuffer that corresponds to the ID of the camera that it belongs to(Since we are going to use multiple cameras)